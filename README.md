# TSiriusNLP — классификация отзывов по категориям (XLM-RoBERTa + LoRA/QLoRA)

Проект решает задачу **многоклассовой классификации** отзывов товаров на маркетплейсах.  
Основная цель — присвоить каждому тексту одну из фиксированных товарных категорий (включая класс **«нет товара»**) и обеспечить высокое качество по метрике **Weighted F1**.

---

## Контекст и требования кейса
- **Цель:** автоматическая классификация отзывов по товарным категориям.
- **Метрика качества:** *Weighted F1* (включая «нет товара»).
- **Ограничения:** отсутствие внешних API и внешних данных, инференс ≤ **5 сек/пример**, решение укладывается в **Google Colab T4 (16 GB VRAM)**.
  
Данный проект следует этим требованиям: используется дообучение локальных открытых моделей (без вызова внешних API), пайплайн не трогает тестовый набор до финальной оценки, а инференс оптимизирован под Colab T4. :contentReference[oaicite:0]{index=0}

---

## Модели

- **Базовый классификатор:** `xlm-roberta-base` → `AutoModelForSequenceClassification`  
  (многоязычный трансформер, стабильный на русскоязычных текстах).
- **Zero-shot разметка (weak-labels):** `joeddav/xlm-roberta-large-xnli`  
  (для авторазметки части обучающего набора перед дообучением).
- **Аугментации:**
  - Парафразирование: `cointegrated/rut5-base-paraphraser`
  - Back-translation: `Helsinki-NLP/opus-mt-ru-en` ↔ `…-en-ru`
  - Лёгкие EDA-техники

> Все модели используются локально; внешние платные/сетевые API не вызываются (соответствие ТЗ).

---

## Дообучение

**Основной режим — PEFT/LoRA** (параметро-эффективный fine-tuning):
- *Target modules:* `["query","key","value","dense"]` (или эквивалентные `q/k/v/out` в новых версиях).
- *Сохраняемые модули:* `modules_to_save=["classifier"]` — классификационная голова обучается полностью.
- *Типичные гиперпараметры:* `r=8–16`, `alpha=16–32`, `lora_dropout=0.05–0.10`.

**Опционально — QLoRA** (та же схема, но база квантуется в 4-бит через bitsandbytes):
- Уменьшает VRAM/время, сохраняя качество SFT-уровня.
- Технические нюансы: перенос модели на GPU после подключения адаптера, `use_cache=False`, gradient checkpointing с `use_reentrant=False`.

> Полный fine-tuning всех весов поддерживается, но не является дефолтным из-за ресурсов и риска переобучения.

---

## Пайплайн данных

1. **Weak-labeling (zero-shot):** авторазметка train-данных с сохранением уверенности.
2. **Фильтрация по уверенности:** отбор надёжных примеров; «серая зона» используется для донабора редких классов.
3. **Балансировка классов:** квоты `MIN_PER_CLS / MAX_PER_CLS` выравнивают распределение.
4. **Аугментации (после балансировки):** парафразы, back-translation, EDA — доведение до целевой мощности на класс.
5. **Сплиты и токенизация:** стратифицированный train/valid без утечек (аугментации одного исходника не попадают в оба сплита); токенизация XLM-R.

---

## Обучение, валидация и инференс

- **Оптимизация:** AdamW (`adamw_torch` для LoRA; `paged_adamw_8bit` для QLoRA).
- **Регуляризация:** dropout 0.10–0.20, label smoothing 0.05–0.10, weight decay ≈0.05.
- **Контроль переобучения:** ранняя остановка по `eval_loss` или `weighted_f1`; валидация по шагам/эпохам.
- **Метрика отчёта:** *Weighted F1* на валидации; дополнительно — отчёт по классам и confusion matrix.
- **Скорость инференса:** батчевый режим и короткая последовательность (обычно `max_length≈256`) обеспечивают соответствие ограничению по времени на пример и по памяти Colab T4. :contentReference[oaicite:1]{index=1}

---

## Структура артефактов

- **Ноутбук:** `TSiriusNLP.ipynb` — полный пайплайн (от weak-labeling до инференса и экспорта).
- **Чекпойнты:**
  - Адаптеры LoRA (лёгкая доставка/версии).
  - (Опционально) смёрдженный монолитный чекпойнт без PEFT.
- **Выходной файл:** `submission.csv` с предсказаниями на тест (формат соревнования/кейса).

- Стабильность на малых классах растёт при доборе реальных примеров и/или точечных аугментациях.  
- При необходимости — K-fold оценка и усреднение логитов нескольких сидов.  
- Проект совместим с требованиями ТЗ: локальные открытые модели, без внешних API и с ограничениями по времени/ресурсам инференса. :contentReference[oaicite:2]{index=2}
